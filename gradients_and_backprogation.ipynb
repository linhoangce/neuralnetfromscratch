{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The Partial Derivative\n",
    "\n",
    "The **partial derivative** measures how much impact a single input has on a function's output.\n",
    "\n",
    "**The partial derivative** is a single equation, and the full mutivariate function's derivative consists of a set of equations called the **gradient**. In other words, the **gradient** is a vector of the size of inputs containing partial derivative solutions with respect to each of the inputs."
   ],
   "id": "2ab44e391cfca2b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:30:59.812452Z",
     "start_time": "2025-04-04T21:30:59.803508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Forward pass\n",
    "x = [1.0, -2.0, 3.0] # input values\n",
    "w = [-3.0, -1.0, 2.0] # weights\n",
    "b = 1.0 # bias\n",
    "\n",
    "# Multiplying inputs by weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "print(xw0, xw1, xw2, b)\n",
    "# Adding weighted inputs and a bias\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "print(z)"
   ],
   "id": "10e5e26cbf4c1f20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0 2.0 6.0 1.0\n",
      "6.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:00.663499Z",
     "start_time": "2025-04-04T21:31:00.656106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "print(y)\n"
   ],
   "id": "9e7dc2585112376",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:00.876910Z",
     "start_time": "2025-04-04T21:31:00.870520Z"
    }
   },
   "cell_type": "code",
   "source": "# Backward pass",
   "id": "95afa635f6188f5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:01.072965Z",
     "start_time": "2025-04-04T21:31:01.059796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The derivative from the next layer\n",
    "dvalue = 1.0\n",
    "\n",
    "# Derivative of ReLU and the chain rule\n",
    "drelu_dz = dvalue * (1. if z > 0 else 0.)\n",
    "drelu_dz"
   ],
   "id": "3f4f4d5f08a8afec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "During the backward pass, we'll calculate the derivative of the loss function, and use it to multiply with the derivative of the activation function of the output layer, then use this result to multiply by the derivative of the output layer, and so on, through all of the hidden layers and activation functions. Inside these layers, the derivative with respect to the weights and biases will form the gradients that we'll use to update the weights and biases. The derivatives with respect to inputs will form the gradient to chain with the previous layer. This layer can calculate the impact of its weights and biases on the loss and backpropagate gradients on inputs further.",
   "id": "e429f2a7fd30b9c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Moving backward through our neural network, the function that comes immediately before we perform the activation function is the **sum of the weighted inputs and bias**. This means that we want to calculate the partial derivative of the sum function, and then, using the chain rule, multiply this bby the partial derivative of the subsequent, outer function, which is ReLU.\n",
    "\n",
    "**The partial derivative of the sum operation is always 1, no matter the inputs**\n",
    "\n",
    "The weighted inputs and bias are summed at this state. So we will caclulate the partial derivatives of the sum operation with respect to each of these, multiplied by the partial derivative for the subsequent function (using the chain rule), which is the ReLU function."
   ],
   "id": "1bd4e0cdebdc7733"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:01.538147Z",
     "start_time": "2025-04-04T21:31:01.527119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Forward pass\n",
    "x = [1., -2., 3.]\n",
    "w = [-3., -1, 2.]\n",
    "b = 1.\n",
    "\n",
    "# Multiply inputs by weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "\n",
    "# Adding the weighted inputs and a bias\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "\n",
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "\n",
    "# Backward pass\n",
    "\n",
    "# The derivative from the next layer\n",
    "dvalue = 1.0\n",
    "\n",
    "# Derivative of ReLU and the chain rule\n",
    "drelu_dz = dvalue * (1. if z > 0 else 0.)\n",
    "print(drelu_dz)\n",
    "\n",
    "# Partial derivatives of the multiplication, the chain rule\n",
    "dsum_dxw0 = 1   # The partial derivative of the sum operation is always 1, no matter the input\n",
    "dsum_dxw1 = 1\n",
    "dsum_dxw2 = 1\n",
    "dsum_db = 1\n",
    "\n",
    "drelu_dxw0 = drelu_dz * dsum_dxw0\n",
    "drelu_dxw1 = drelu_dz * dsum_dxw1\n",
    "drelu_dxw2 = drelu_dz * dsum_dxw2\n",
    "drelu_db = drelu_dz * dsum_db\n",
    "print(drelu_dxw0, drelu_dxw1, drelu_dxw2, drelu_db)"
   ],
   "id": "572bc5e06cd27938",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Continuing backward, the function that comes before the sum is the multiplication of weights and inputs. The derivative for a product is whatever the inputs is being multiplied by.\n",
    "\n",
    "`f(x,y) = xy` -> `df(x,y)/dx = y`, `df(x,y)/dy = x`\n",
    "\n",
    "The partial derivative of f w.r.t `x` equals `y`, and vice versa. Following this rule, the partial derivative of the first *weighted input* with respect to the *input* equals the *weight*. Then, we have to apply the chain rule and mutiply this partial derivative with partial derivative of the subsequent function, which is the sum."
   ],
   "id": "5dd055464e9fa5e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:01.909892Z",
     "start_time": "2025-04-04T21:31:01.900085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Partial derivatives of the multiplication, the chain rule\n",
    "dmul_dx0 = w[0]\n",
    "dmul_dx1 = w[1]\n",
    "dmul_dx2 = w[2]\n",
    "dmul_dw0 = x[0]\n",
    "dmul_dw1 = x[1]\n",
    "dmul_dw2 = x[2]\n",
    "\n",
    "drelu_dx0 = drelu_dxw0 * dmul_dx0\n",
    "drelu_dx1 = drelu_dxw1 * dmul_dx1\n",
    "drelu_dx2 = drelu_dxw2 * dmul_dx2\n",
    "drelu_dw0 = drelu_dxw0 * dmul_dw0\n",
    "drelu_dw1 = drelu_dxw1 * dmul_dw1\n",
    "drelu_dw2 = drelu_dxw2 * dmul_dw2\n",
    "\n",
    "print(drelu_dx0, drelu_dw0, drelu_dx1, drelu_dw1, drelu_dx2, drelu_dw2)"
   ],
   "id": "74e4633eeb2c0f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0 1.0 -1.0 -2.0 2.0 3.0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We applied the chain rule to calculate the partial derivative of the ReLU activation function with respect to the first input, `x0`. We can simplify them:\n",
    "`\n",
    "drelu_dx0 = drelu_dxw0 * dmul_dx0\n",
    "`\n",
    "\n",
    "where:\n",
    "`dmul_dx0 = w[0]`\n",
    "\n",
    "then:\n",
    "\n",
    "`drelu_dx0 = drelu_dxw0 * w[0]`\n",
    "\n",
    "where:\n",
    "\n",
    "`drelu_dxw0 = drelu_dz *dsum_dxw0`\n",
    "\n",
    "then:\n",
    "\n",
    "`drelu_dx0 = drelu_dz * dsum_dxw0 * w[0]`\n",
    "\n",
    "where:\n",
    "\n",
    "`dsum_dxw0 = 1`\n",
    "\n",
    "then:\n",
    "\n",
    "`drelu_dx0 = drelu_dz * 1 * w[0] = drelu_dz * w[0]`\n",
    "\n",
    "where:\n",
    "\n",
    "`drelu_dz = dvalue * (1. if z > 0 else 0.)`\n",
    "\n",
    "then:\n",
    "\n",
    "`drelu_dx0 = dvalue * (1. if z > 0 else 0.) * w[0]`\n",
    "`"
   ],
   "id": "7cf7bbc4d31d9e8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The partial derivative of a neuron's function, with respect to the weight, is th einput related to this weight, and, with respect to the input, is the related weight. The partial derivative of the neuron's function with respect to the bias is always 1.\n",
    "\n",
    "We multiply them with the derivative of the subsequent function (which was 1 in this example) to get the final derivatives.\n",
    "\n",
    "All together, the partial derivatives above, combined into a vector, make up our gradients."
   ],
   "id": "b1c79cfa3da109c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:02.430076Z",
     "start_time": "2025-04-04T21:31:02.424014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dx = [drelu_dx0, drelu_dx1, drelu_dx2]\n",
    "dw = [drelu_dw0, drelu_dw1, drelu_dw2]\n",
    "db = drelu_db"
   ],
   "id": "a174016ffbc52452",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now apply these gradients to the weights to hopefully minimize the output. This typically the purpose of the **optimizer**. We apply a negative fraction to this gradient since we want to decrease the final output value, and the gradient shows the direction of the steepest ascent. For example, our current weights and bias are:",
   "id": "a7e55168e33785b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:02.777591Z",
     "start_time": "2025-04-04T21:31:02.769987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We can then apply a fraction of the gradients to these values:\n",
    "\n",
    "w[0] += -0.001 * dw[0]\n",
    "w[1] += -0.001 * dw[1]\n",
    "w[2] += -0.001 * dw[2]\n",
    "b += -0.001 * db\n",
    "\n",
    "print (w, b)"
   ],
   "id": "6f2914445f0c2965",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.001, -0.998, 1.997] 0.999\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we've slightly changed the weights and bias in such a way so as to decrease the output somewhat intelligently. We can see the effects of our tweaks on the output by doing another forward pass:",
   "id": "cb1a25d3d701cc85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:03.152388Z",
     "start_time": "2025-04-04T21:31:03.143189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Multiplying inputs by weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "\n",
    "# Adding\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "\n",
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "y"
   ],
   "id": "c86bf86c0ab2674e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.985"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We want to decrease the loss value, which is the last calculation in the chain of calculations during the forward pass, and it's the first one to calculate the gradient during backpropagation.\n",
    "\n",
    "Now, we'll apply the one-neuron example to the list of samples and expand it to an entire layer of neurons. To begin, let's set a list of 3 samples for inputs, where each sample consists of 4 features. For this example, our network will consist of a single hidden layer, containing 3 neurons (lists of 3 weight sets and 3 biases).\n",
    "\n",
    "A single neuron of the current layer connects to all of the multiple neurons in the following layer - they all receive the output of this neuron. Each neuron from the next layer will return a partial derivative of its function with respect to this input. The neuron in the current layer will receive a vector consisting of these derivatives. We need this to be a singular value for a singular neuron. To continue backpropagation, we need to sum this vector.\n",
    "\n",
    "As opposed to a single neuron, a layer outputs a vector of values instead of a singular value. Each neuron in a layer connects to all of the neurons in the next layer. During backpropagation, each neuron from the current layer will receive a vector of partial derivatives the same way that we described for a single neuron. With a layer of neuron, it'll take the form of a list of these vectors, or a 2D array. We know that we need to perform a sum, but what should we sum and what is the result supposed to be?\n",
    "\n",
    "Each neuron is going to output a gradient of the partial derivatives with respect to all of its inputs, and all neurons will form a list of these vectors. We need to sum along the inputs -- the first input to all of the neurons, the second input, and so on. We'll have to sum columns.\n",
    "\n",
    "To calculate the partial derivative with respect to inputs, we need the weights -- the partial derivative with respect to the inputs equals the related weight. This means that the array of partial derivatives with respect to all of the inputss equals the array of weights. Since this array is transposed, we'll need to sum its rows instead of columns. To apply the chain rule, we need to multiply them by the gradient fro the subsequent function.\n",
    "\n",
    "In the code to show this, we take the transposed weights, which are the transposed array of the derivaties with respect to inputs, and multiply them by their respective gradients (related to given neurons) to apply the chain rule. Then we sum along with the inputs. Then we calculate the gradient for the next layer in backpropagation. The \"next\" layer in backpropagation is the previous layer in the order of creation of the model:"
   ],
   "id": "7aa974b5087de00e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:05.844925Z",
     "start_time": "2025-04-04T21:31:03.517238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use a vecotr of 1s\n",
    "dvalues = np.array([[1., 1., 1.]])\n",
    "\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "\n",
    "# sum weights of given input\n",
    "# and multiply by the passed in gradient for this neuron\n",
    "dx0 = sum(weights[0]*dvalues[0])\n",
    "dx1 = sum(weights[1]*dvalues[0])\n",
    "dx2 = sum(weights[2]*dvalues[0])\n",
    "dx3 = sum(weights[3]*dvalues[0])\n",
    "\n",
    "dinputs = np.array([dx0, dx1, dx2, dx3])\n",
    "\n",
    "dinputs"
   ],
   "id": "818e598d8f273639",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44, -0.38, -0.07,  1.37])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`dinputs` is a gradient of the neuron function with respect to inputs.\n",
    "\n",
    "We defined the gradient of the subsequent function (dvalues) as a row vector. From NumPy's perspective, and since both weights and dvalues are NumPy arrays, we can simplify the dx0 to dx3 calculation. Since the weights array is formatted so that the rows contain weights related to each input (weights for all neurons for the given input), we can multiply them by the gradient vector directly:"
   ],
   "id": "2542385a8571db8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\"The sum of the multiplication of the elements is the dot product. We can achieve the same result by using `np.dot` function. For this to be possible, we need to match the \"inner\" shapes and decide the first dimension of the result, which is the first dimension of the first parameter. We want the output of this calculation to be the shape of the gradient from the subsequent function -- recall that we have one partial derivative for each neuron and multiply it by the neuron's partial derivative with respect to its input. We then want to multiply each of these gradients with each of the partial derivatives that are related to this neuron's input and we already noticed that they are row. The dot product takes rows from the first argument and columns from the second to perform multiplication and sum; this, we need to transpose the weights for this calculation.",
   "id": "4dc95e832ca836ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:05.922883Z",
     "start_time": "2025-04-04T21:31:05.912123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# a vector of 1s\n",
    "dvalues = np.array([[1., 1., 1.]])\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "\n",
    "# sum weights of given inputs and multiply by the passed in gradients for this neuron\n",
    "dinputs = np.dot(dvalues[0], weights.T)\n",
    "\n",
    "dinputs"
   ],
   "id": "bebd92f0e9ea9587",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44, -0.38, -0.07,  1.37])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We have to account for more thing - a batch of samples. So far, we have been using a single sample responsible for a single gradient vector thay is backpropagated between layers. The row vector that we created for `dvalue` is in preparation for a batch of data. With more samples, the layer will return a list of gradients, which we almost handle correctly for. Let's replace the singular gradient `dvalues[0]` with a full list of gradients, `dvalues`, and add more example gradients to this list:\n",
    "\n",
    "\n"
   ],
   "id": "6ccd4226cc499596"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:05.991910Z",
     "start_time": "2025-04-04T21:31:05.979523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "\n",
    "# sum weights of given input and multiply by the passed in gradient for this neuron\n",
    "dinputs = np.dot(dvalues, weights.T)\n",
    "\n",
    "dinputs"
   ],
   "id": "8d92823f0d9ca0d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44, -0.38, -0.07,  1.37],\n",
       "       [ 0.88, -0.76, -0.14,  2.74],\n",
       "       [ 1.32, -1.14, -0.21,  4.11]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calculating the gradients with respect to weights is very simialr, but in this case, we're going to be using gradient to update the weights, so we need to match the shape of weights, not inputs. Since the derivative with respect to the weights equals inputs, weights are transposed, so we need to transpose inputs to receive the derivative of the neuron with respect to weights. Then we use these transposed inputs as the first parameter to the dot product - the dot product is going to multiply rows by inputs, where each row, as it is transposed, contains data for a given input for all of the samples, by the columns of `dvalues`. These columns are related to the outputs of singular neurons for all of the samples, so the result will contain an array with the shape of the weights, containing the gradients with respect to the inputs, multiplied with the incoming gradient for all of the samples in the batch:\n",
   "id": "211f171df6bfc900"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:06.192641Z",
     "start_time": "2025-04-04T21:31:06.182589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# We have 3 sets of inputs - samples\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                    [2., 5., -1., 2],\n",
    "                    [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "# sum weights of given input\n",
    "# and multiply by the passed in gradient for this neuron\n",
    "dweights = np.dot(inputs.T, dvalues)\n",
    "\n",
    "print(dweights)"
   ],
   "id": "4ec668f52383df21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5  0.5]\n",
      " [20.1 20.1 20.1]\n",
      " [10.9 10.9 10.9]\n",
      " [ 4.1  4.1  4.1]]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The output's shape matches the shape of weights because we summed the inputs for each weight and then multiplied them by the input gradient. `dweights` is a gradient of the neuron function with respect to the weights.\n",
    "\n",
    "For the biases and derivatives with respect to them, the derivatives come from the sum operation and always equal 1, multiplied by the imcoming gradients to apply the chain rule. Since gradients are a list of gradients (a vector of gradients for each neuron for all samples), we just have to sum them with the neurons, column-wise, along axis 0."
   ],
   "id": "a5d8978db309f19a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:06.772449Z",
     "start_time": "2025-04-04T21:31:06.758230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# One bias for each neuron\n",
    "# biases are the row vector with a shape (1, neurons)\n",
    "biases = np.array([[2, 3, 0.5]])\n",
    "\n",
    "# dbiases - sum values, do this over samples (first axis), keepdims\n",
    "# since this by default will produce a plain list\n",
    "dbiases = np.sum(dvalues, axis=0, keepdims=True) # keepdims lets us keep the gradient as a row vector\n",
    "\n",
    "dbiases"
   ],
   "id": "2355804ec3e6feb9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 6., 6.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The last thing is the derivative of the ReLU function. It equals 1 if the input is greater than 0 and 0 otherwise. The layer passes its outputs through the `ReLU()` activation during the forward pass. For the backward pass, `ReLU()` receives a gradient of the same shape. The derivative of the ReLU function will form an array of the same shape, filled with 1 when the related input is greater than 0, and 0 otherwise.\n",
    "\n",
    "To calculate the ReLU derivative, we created an array filled with zeros. `np.zeros_like` is a NumPy function that creates an array filled with zeros, with the shape of the array from its parameter, the `z` array in our case, which is an example output of the neuron. Following the `ReLU()` derivative, we then set the values related to the inputs greater than 0 as 1. In the end, we multuply this array with the gradient of the subsequent function and print the result."
   ],
   "id": "a8481d3b2d26ba75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:10.163684Z",
     "start_time": "2025-04-04T21:31:10.154472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example layer output\n",
    "z = np.array([[1, 2, -3, -4],\n",
    "              [2, -7, -1, 3],\n",
    "              [-1, 2, 5, -1]])\n",
    "\n",
    "dvalues = np.array([[1,2,3,4],\n",
    "                    [5,6,7,8],\n",
    "                    [9,10, 11, 12]])\n",
    "\n",
    "# ReLU activation's derivative\n",
    "drelu = np.zeros_like(z)\n",
    "drelu[z > 0] = 1\n",
    "\n",
    "print(drelu)\n",
    "\n",
    "# The chain rule\n",
    "drelu *= dvalues\n",
    "\n",
    "print(drelu)"
   ],
   "id": "b3f33336261df740",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0]\n",
      " [1 0 0 1]\n",
      " [0 1 1 0]]\n",
      "[[ 1  2  0  0]\n",
      " [ 5  0  0  8]\n",
      " [ 0 10 11  0]]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now simplify this operation. Since the `ReLU()` derivative array is filled with 1s, which do not change the values multiplied by them, and 0s that zero the multiplying values, this means that we can take the gradients of the subsequent function and set to 0 all  of the values that correspond to the `ReLU()` input and are equal to or less than 0.",
   "id": "24741c675574892a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:10.575523Z",
     "start_time": "2025-04-04T21:31:10.567968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example layer output\n",
    "z = np.array([[1, 2, -3, -4],\n",
    "                [2, -7, -1, 3],\n",
    "                [-1, 2, 5, -1]])\n",
    "\n",
    "dvalues = np.array([[1, 2, 3, 4],\n",
    "                    [5, 6, 7, 8],\n",
    "                    [9, 10, 11, 12]])\n",
    "\n",
    "# ReLU activation's derivative with the chain rule applied\n",
    "drelu = dvalues.copy()\n",
    "drelu[z <= 0] = 0\n",
    "\n",
    "print(drelu)"
   ],
   "id": "2fc2cdeacc56aa56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  0  0]\n",
      " [ 5  0  0  8]\n",
      " [ 0 10 11  0]]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Summarize",
   "id": "cbcb845cca97c282"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:10.924759Z",
     "start_time": "2025-04-04T21:31:10.907986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# We have 3 sets of inputs - samples\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                    [2., 5., -1., 2],\n",
    "                    [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "\n",
    "# One bias for each neuron\n",
    "# biases are the row vector with a shape (1, neuron)\n",
    "biases = np.array([[2, 3, 0.5]])\n",
    "\n",
    "# Forward pass\n",
    "layer_outputs = np.dot(inputs, weights) + biases # Dense layer\n",
    "relu_outputs = np.maximum(0, layer_outputs) # ReLU activation\n",
    "\n",
    "# Let's optimize and test backpropagation here\n",
    "# reLU activation - simulates derivative with respect to input values\n",
    "# from next layer passed to currently layer during backpropagation\n",
    "drelu = relu_outputs.copy()\n",
    "drelu[layer_outputs <= 0] = 0\n",
    "\n",
    "# Dense layer\n",
    "# dinputs - multiply by weights\n",
    "dinputs = np.dot(drelu, weights.T)\n",
    "\n",
    "#dweights - nultiply by inputs\n",
    "dweights = np.dot(inputs.T, drelu)\n",
    "\n",
    "# dbiases - sum values, do this over samples (first axis), keepdims\n",
    "dbiases = np.sum(drelu, axis=0, keepdims=True)\n",
    "\n",
    "# Update parameters\n",
    "weights += -0.001 * dweights\n",
    "biases += -0.001 * dbiases\n",
    "\n",
    "weights, biases"
   ],
   "id": "b36aead834ae3d8c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.179515 ,  0.5003665, -0.262746 ],\n",
       "        [ 0.742093 , -0.9152577, -0.2758402],\n",
       "        [-0.510153 ,  0.2529017,  0.1629592],\n",
       "        [ 0.971328 , -0.5021842,  0.8636583]]),\n",
       " array([[1.98489 , 2.997739, 0.497389]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Replaced with NumPy variants",
   "id": "17318cadc64ffc07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:10.991484Z",
     "start_time": "2025-04-04T21:31:10.984254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, inputs, neurons):\n",
    "        self.weights = 0.01 * np.random.randn(inputs, neurons)\n",
    "        self.biases = np.zeros((1, neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n"
   ],
   "id": "de3b34023b1e7dad",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:11.168113Z",
     "start_time": "2025-04-04T21:31:11.161076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)"
   ],
   "id": "fd7e0c940d8b2f2e",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "During the `forward` method for our `Layer_Dense` class, we will want to remember what the inputs were (we'll need them when calculating the partial deriavtive with respect to weights during backpropagation), which can be easily implemented using an object property:",
   "id": "4e226995ea6a6288"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T22:11:56.161466Z",
     "start_time": "2025-04-04T22:11:56.152071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer_Dense:\n",
    "\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs # save the inputs for calculating derivatives during backpropagation\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues,\n",
    "                              axis=0,\n",
    "                              keepdims=True)\n",
    "\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n"
   ],
   "id": "7ab52b6447490633",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:11.391039Z",
     "start_time": "2025-04-04T21:31:11.382590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Activation_ReLU:\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Since we need to modify the original variable,\n",
    "        # let's make a copy of the values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # Zero gradients where input values were 0 or negative\n",
    "        self.dinputs[self.inputs <= 0] = 0"
   ],
   "id": "68843280d4facfa6",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Categorical Cross-entropy loss derivative\n",
    "\n",
    "The derivative of the negative log likelihood loss function with respect to its inputs (predicted values at the i-th sample) equals the negative ground-truth vector, divided by the vector of the predicted values (which is also the output vector of the softmax function)"
   ],
   "id": "2d1b3f3b997442f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:11.533827Z",
     "start_time": "2025-04-04T21:31:11.526024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Loss:\n",
    "\n",
    "    def calculate(self, outputs, y):\n",
    "\n",
    "        # calculate the sample losses\n",
    "        sample_losses = self.forward(outputs, y)\n",
    "\n",
    "        # calculate the mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        return data_loss"
   ],
   "id": "8db5a9081cad7b4f",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:11.609310Z",
     "start_time": "2025-04-04T21:31:11.600467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Probabilities for target values - only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped * y_true,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihood = -np.log(correct_confidences)\n",
    "\n",
    "        return negative_log_likelihood\n",
    "\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n"
   ],
   "id": "5a48edd3068ca4a3",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Along with the partial derivativa calculation, we are performing two additional operations. First, we're turning numerical labels into one-hot encoded vectors - prior to this, we need to check how many dimensions y_tru consists of. If the shape of the labels returns a single dimension (which means that they are shaped like a list and nost like an array), they consist of discrete numbers and need to be converted to a list of one-hot encoded vectors - a two-dimensional array. If that's the case, we need to turn them into one-hot encoded vectors. We'll use the `np.eye` method which, given a number `n`, return `nxn` array filled with `1` on yhr diagonal and `0` everywhere else.\n",
   "id": "3adb9b259529ac76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:11.722569Z",
     "start_time": "2025-04-04T21:31:11.714377Z"
    }
   },
   "cell_type": "code",
   "source": "print(np.eye(5))",
   "id": "85616d4b31e0cb59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:11.797099Z",
     "start_time": "2025-04-04T21:31:11.788630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = Loss_CategoricalCrossentropy()\n",
    "test"
   ],
   "id": "117856af4ae10b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Loss_CategoricalCrossentropy at 0x2464c5ff620>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The second operation is the gradient normalization. Optimizers sum all of the gradients related to each weight and bias before multiplying them by the learning rate (or some other factor). What this means, in our case, is that the more samples we have in a dataset, the more gradient sets we'll receive at this step, and the bigger this sum will become. As a consequence, we'll have to adjust the learning rate according to each set of samples. To solve this problem, we can divide all of the gradients by the number of samples. A sum of elements divided by a count of them is their mean value -- this way, we'll effectively normalize the gradients and make their sum's magnitude invariant to the number of samples.",
   "id": "6c818bcaa1c19b60"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Softmax activation derivative",
   "id": "d8d8b5505efe787a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:11.909941Z",
     "start_time": "2025-04-04T21:31:11.903379Z"
    }
   },
   "cell_type": "code",
   "source": "softmax_output = [0.7, 0.1, 0.2]",
   "id": "213786ff1de4886",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:11.984450Z",
     "start_time": "2025-04-04T21:31:11.976697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "softmax_output = np.array(softmax_output).reshape(-1, 1)\n",
    "print(softmax_output)"
   ],
   "id": "9d8e9b182fcaca96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7]\n",
      " [0.1]\n",
      " [0.2]]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The left side of the equation is Softmax's output multiplied by the Kronecker delta. The Kronecker delta equals *l* when both inputs are equal and *0* otherwise. If we visualize this as an array, we'll have an array of zeros with ones on the diagonal - we implemented such a solution using the `np.eye` method",
   "id": "e6a2eea5b47f66d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:12.156639Z",
     "start_time": "2025-04-04T21:31:12.148142Z"
    }
   },
   "cell_type": "code",
   "source": "print(np.eye(softmax_output.shape[0]))",
   "id": "32c467d2d4d3eee0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:12.232743Z",
     "start_time": "2025-04-04T21:31:12.223499Z"
    }
   },
   "cell_type": "code",
   "source": "softmax_output.shape",
   "id": "5d6e91f8dccd0953",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:12.336802Z",
     "start_time": "2025-04-04T21:31:12.328188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now we'll do the multiplication of both of the values from the equation part\n",
    "\n",
    "print(softmax_output * np.eye(softmax_output.shape[0]))"
   ],
   "id": "8d0e2b73de702fd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7 0.  0. ]\n",
      " [0.  0.1 0. ]\n",
      " [0.  0.  0.2]]\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:12.523466Z",
     "start_time": "2025-04-04T21:31:12.513799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We can optimize this by using `np.diagflat` method which creates an array using an input vector as the diagonal\n",
    "np.diagflat(softmax_output)"
   ],
   "id": "d680ca9cde6747fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7, 0. , 0. ],\n",
       "       [0. , 0.1, 0. ],\n",
       "       [0. , 0. , 0.2]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The other part of the equation is S_i,j*S_i,k - the multiplication of the Softmax outputs, iterating over the *j* and *k* indices respectively. Since for each sample (the *i* index), we'll have to multiply the values from the Softmax function's output (in all of the combinations), we can use the dot product operation. For this, we'll have to transpose the second argument to get its row vector form:\n",
   "id": "f25857a0e6bf9ab7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:12.692868Z",
     "start_time": "2025-04-04T21:31:12.686613Z"
    }
   },
   "cell_type": "code",
   "source": "print(np.dot(softmax_output, softmax_output.T))",
   "id": "b0956839b30a1ad5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49 0.07 0.14]\n",
      " [0.07 0.01 0.02]\n",
      " [0.14 0.02 0.04]]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:12.988070Z",
     "start_time": "2025-04-04T21:31:12.979173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The derivative of the Softmax output\n",
    "print(np.diagflat(softmax_output) -\n",
    "      np.dot(softmax_output, softmax_output.T))"
   ],
   "id": "16a708bf9406f048",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21 -0.07 -0.14]\n",
      " [-0.07  0.09 -0.02]\n",
      " [-0.14 -0.02  0.16]]\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The maxtrix result of the equation and the array solution above is called **Jacobian matrix**, in this case, an array of partial derivatives in all of the combinations of both input vectors. We are calculating the partial redivatives of every output of the Softmax function with respect to each input seperately. We do this because each input influences each output due to the normalization process, which takes the sum of all the exponentialed inputs. The result of this operation, performed on a batch of samples, is a list of the Jacobian matrices, which effectively forms a 3D matrix - which can be visualized as a column whose levels are Jacobian matrices being the sample-wise gradient of the Softmax function.\n",
    "\n",
    "This raises a question - if sample-wise gradients are the Jacobian matrices, how do we perform the chain rule with the gradient back-propagated from the loss function, since it's a vector for each sample? Also, what do we do with the fact that the previous layer, which is the Dense Layer, will expect the gradients to be a 2D array? Currently, we have a 3D array of the partial derivatives - a list of Jacobian matrices. The derivative of the Softmax function with respect to any of its inputs returns a vector of partial derivatives ( a row from the Jacobian matrix), as this input influences all the output, thus also influencing the partial derivative for each of them. We need to sum the values from these vectors so that each of the inputs for each of the samples will return a single partial derivative value instead. Because each input influences all of the outputs, the returned vector of the partial derivatives has to be summed up for the final partial derivative with respect to this input. We can perform this operation on each of the Jacobian matrices directly, applying the chain rule at the same time (applying the gradient from the loss function) using `np.dot()` - For each sample, it'll take the row from the Jacobian matrix and multiply it by the corresponding value from the loss function's gradient. As a result, the dot product of each of these vectors and values will return a singular value, forming a vector of the partial derivatives sample-wise and a 2D array (a list of resulting vectors) batch-wise.\n"
   ],
   "id": "7b571d1fb547f128"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:13.202200Z",
     "start_time": "2025-04-04T21:31:13.192481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "First, we create an empty array (which will become the resulting gradient array) with the same shape as the gradients that we're receiving to apply the chain rule, using `np.empty_like()`.\n",
    "\n",
    "In the next step, we're going to iterate sample-wise over pairs of the outputs and gradients, calculating the partial derivatives as described earlier and calculating the final product (applying the chain rule) of the Jacobian matrix and gradient vector (from the passed-in gradient array), storing the resulting vector as a row in the dinput array. We're going to store each vector in each row while iterating, forming the output array.\n",
    "\"\"\"\n",
    "\n",
    "class Activation_Softmax:\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Set unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumberate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "            # Calculate sample-wise gradient and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)"
   ],
   "id": "31d0ff0d8f9ed1fe",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To implement the solution y-hat - y_i,k instead of performing the subtraction of the full arrays, we're taking advantage of the fact that the *y* being `y_true` in the code consists of one-hot encoded vectors, which means that, for each sample, there is only a singular value of `1` in these vectors and the remaining positions are filled with zeros.\n",
    "\n",
    "This means that we can use NumPy to index the prediction array with the sample number and its true value index, subtracting `1` from these values. This operation requires discrete true labels instead of one-hot encoded ones, thus the additional code that performs the transformation if needed - If the number of dimensions in the ground-truth array equals 2, it means that it's a matrix consisting of one-hot encoded vectors. We can use `np.argmax()`, which returns the index of the maximum value (index for `1` in this case), but we need to perform this operation sample-wise to get a vector of indices.\n",
    "\n",
    "For the last step, we normalize the gradient in exactly the same way and for the same reason as described along with the Categorical Cross-Entropy gradient normalization."
   ],
   "id": "274d22ec09c50937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:13.342819Z",
     "start_time": "2025-04-04T21:31:13.334084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_true = np.array([[1,0,0],[0,0,1],[0,1,0]])\n",
    "np.argmax(y_true).item()"
   ],
   "id": "9a5e5eba008c18fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:13.446015Z",
     "start_time": "2025-04-04T21:31:13.437585Z"
    }
   },
   "cell_type": "code",
   "source": "np.argmax(y_true, axis=1)\n",
   "id": "576693e30370245",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:13.569165Z",
     "start_time": "2025-04-04T21:31:13.560810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Softmax classifier - combined Softmax activation\n",
    "# and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "\n",
    "    # Creates activation and loss function objects\n",
    "    def __init(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "\n",
    "        # Caclulate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(y_true)\n",
    "\n",
    "        # If labels are one-hot encoded, turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Calculate gradients\n",
    "        self.dinputs [range(samples), y_true] -= 1\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples"
   ],
   "id": "918cd46efd98258c",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Code Summarized",
   "id": "e960687147c29071"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:13.652815Z",
     "start_time": "2025-04-04T21:31:13.636589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs,\n",
    "                                            axis=1,\n",
    "                                            keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values,\n",
    "                                            axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(\n",
    "            self.output, dvalues\n",
    "        )):\n",
    "\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "            # Calculate sample-wise gradient and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
    "                                         single_dvalues)\n",
    "\n",
    "\n",
    "# Cross-Entropy Loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Probabilities for target values only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped * y_true,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihood = -np.log(correct_confidences)\n",
    "\n",
    "        return negative_log_likelihood\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "# Softmax classifier - combined Softmax activation\n",
    "# and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "\n",
    "    # Create activation and loss function objects\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "\n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # If labels are one-hot encoded, turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # Calculate gradients\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "\n",
    "        # Normalize gradients\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n"
   ],
   "id": "f89e969e7ebe66ee",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now test if the combined backward step returns the same values compared to when we backpropagate gradients through both of the functions separately. We'll make up an output for the Softmax function and some target values.",
   "id": "2b05aefda399181d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:31:14.483100Z",
     "start_time": "2025-04-04T21:31:13.938946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
    "                            [0.1, 0.5, 0.4],\n",
    "                            [0.02, 0.9, 0.08]])\n",
    "\n",
    "class_targets = np.array([0, 1, 1])\n",
    "\n",
    "softmax_loss = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "softmax_loss.backward(softmax_outputs, class_targets)\n",
    "dvalues1 = softmax_loss.dinputs\n",
    "\n",
    "activation = Activation_Softmax()\n",
    "activation.output = softmax_outputs\n",
    "loss = Loss_CategoricalCrossentropy()\n",
    "loss.backward(softmax_outputs, class_targets)\n",
    "activation.backward(loss.dinputs)\n",
    "dvalues2 = activation.dinputs\n",
    "\n",
    "print(f'Gradients: combined loss and activation: \\n{dvalues1}')\n",
    "print(f'Gradients: separate loss and activation: \\n{dvalues2}')\n"
   ],
   "id": "b8c484c4f3623ea3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients: combined loss and activation: \n",
      "[[-0.1         0.03333333  0.06666667]\n",
      " [ 0.03333333 -0.16666667  0.13333333]\n",
      " [ 0.00666667 -0.03333333  0.02666667]]\n",
      "Gradients: separate loss and activation: \n",
      "[[-0.09999999  0.03333334  0.06666667]\n",
      " [ 0.03333334 -0.16666667  0.13333334]\n",
      " [ 0.00666667 -0.03333333  0.02666667]]\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The results are the same. To answer the question of how manu times faster this solution is, we can take advantage of Python's timeit module, running both solutions multiple times and combining the execution times.",
   "id": "16ead1a431b6ac34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T21:32:28.008198Z",
     "start_time": "2025-04-04T21:32:25.666428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from timeit import timeit\n",
    "\n",
    "def f1():\n",
    "    softmax_loss = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "    softmax_loss.backward(softmax_outputs, class_targets)\n",
    "    dvalues1 = softmax_loss.dinputs\n",
    "\n",
    "def f2():\n",
    "    activations = Activation_Softmax()\n",
    "    activation.output = softmax_outputs\n",
    "    loss = Loss_CategoricalCrossentropy()\n",
    "    loss.backward(softmax_outputs, class_targets)\n",
    "    activation.backward(loss.dinputs)\n",
    "    dvalues = activation.dinputs\n",
    "\n",
    "t1 = timeit(lambda: f1(), number=10000)\n",
    "t2 = timeit(lambda: f2(), number=10000)\n",
    "t2/t1"
   ],
   "id": "c239287a2a1de08",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.251972962789033"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Full model code:",
   "id": "fec12ef8555a741a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T22:12:01.002483Z",
     "start_time": "2025-04-04T22:12:00.984801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense Layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 3 inputs features (as we take output\n",
    "# of previous layer here) and 3 output values\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Perform a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "# Perform a forward pass through activation function\n",
    "# takes the output of first dense layer here\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "# Perform a forward pass through second Dense layer\n",
    "# takes outputs of activation function of first layer as inputs\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "# Perform a forward pass through the activation/loss function\n",
    "# takes the output of second dense layer here and returns loss\n",
    "loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "# Let's see output of the first few samples:\n",
    "print(loss_activation.output[:5])\n",
    "\n",
    "# Print loss value\n",
    "print('loss:', loss)\n",
    "\n",
    "# Calculate accuracy from output of activation2 and targetys\n",
    "# calculate values along first axis\n",
    "predictions = np.argmax(loss_activation.output, axis=1)\n",
    "if len(y.shape) == 2:\n",
    "    y = np.argmax(y, axis=1)\n",
    "\n",
    "accuracy = np.mean(predictions==y)\n",
    "\n",
    "print(f'acc: {accuracy}')\n",
    "\n",
    "# Backward pass\n",
    "loss_activation.backward(loss_activation.output, y)\n",
    "dense2.backward(loss_activation.dinputs)\n",
    "activation1.backward(dense2.dinputs)\n",
    "dense1.backward(activation1.dinputs)\n",
    "\n",
    "print(dense1.dweights)\n",
    "print(dense1.dbiases)\n",
    "print(dense2.dweights)\n",
    "print(dense2.dbiases)\n",
    "\n"
   ],
   "id": "f4070a34a2633702",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333302 0.33333305 0.3333339 ]\n",
      " [0.33333305 0.3333331  0.33333382]\n",
      " [0.33333272 0.33333293 0.33333433]\n",
      " [0.33333254 0.3333328  0.33333465]]\n",
      "loss: 1.0986078\n",
      "acc: 0.3433333333333333\n",
      "[[1.9607307e-05 1.4678335e-04 4.8484417e-04]\n",
      " [1.3873042e-04 5.6356144e-05 3.6091977e-04]]\n",
      "[[ 0.00012253 -0.00020452 -0.00021316]]\n",
      "[[ 3.09474926e-05 -2.55546125e-04  2.24598611e-04]\n",
      " [ 5.08814919e-05  5.08635494e-05 -1.01745034e-04]\n",
      " [ 1.09283050e-04  4.17974188e-05 -1.51080458e-04]]\n",
      "[[-1.1696364e-05 -9.6099684e-06  2.1202490e-05]]\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Full code up to this point",
   "id": "ea04a43b693c7323"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:08:47.211684Z",
     "start_time": "2025-04-05T19:08:47.179134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "# Dense Layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, inputs):\n",
    "        # remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify original values,\n",
    "        # let's make a copy of values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # Zero gradient where inputs values are negative or zeros\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "\n",
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs,\n",
    "                                            axis=1,\n",
    "                                            keepdims=True))\n",
    "\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values,\n",
    "                                            axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
    "\n",
    "            # Calculate sample-wise gradienta\n",
    "            # and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
    "                                         single_dvalues)\n",
    "\n",
    "# Common Loss Class\n",
    "class Loss:\n",
    "\n",
    "    # Calculate the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self, output, y):\n",
    "\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        # return loss\n",
    "        return data_loss\n",
    "\n",
    "\n",
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # CLip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Probabilities for target values - only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped * y_true,\n",
    "                exis=1\n",
    "            )\n",
    "\n",
    "        # losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "\n",
    "        return negative_log_likelihoods\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # Number of labels in every samples\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Softmax classifier - combined Softmax activation and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy:\n",
    "\n",
    "    # Creates activation and loss function objects\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "\n",
    "        # Calculate and return loss\n",
    "        return self.loss.calculate(self.output,\n",
    "                                   y_true)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # If labels are one-hot encoded, turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true,\n",
    "                               axis=1)\n",
    "\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # Calculate gradients\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "\n",
    "        # Normalize gradients\n",
    "        self.dinputs = self.dinputs / samples\n"
   ],
   "id": "fbcee260d08b73db",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:09:12.712866Z",
     "start_time": "2025-04-05T19:09:12.693936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create Dense layer with 2 input features and 3 output values\n",
    "dense1 = Layer_Dense(2, 3)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense Layer)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 3 input features (as we take output\n",
    "# of previous layer here) and 3 output values\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "\n",
    "# Create Softmax classifier's combined loss and activation\n",
    "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
    "\n",
    "# Perform a forward pass of our training data through this layer\n",
    "dense1.forward(X)\n",
    "\n",
    "# Perform a forward pass through activation function\n",
    "# takes the output of first dense layer here\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "# Perform a forward pass through second Dense layer\n",
    "# takes outputs of activation funciton of first layer as inputs\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "# Perform a forward pass through the activation/loss function\n",
    "# takes the output of the second dense layer here and return loss\n",
    "loss = loss_activation.forward(dense2.output, y)\n",
    "\n",
    "# Let's see output of the first few samples\n",
    "print(loss_activation.output[:5])\n",
    "\n",
    "# Print loss value\n",
    "print(f\"loss: {loss}\")\n",
    "\n",
    "# Calculate accuracy from output of activation2 and targets\n",
    "# Calculate values along first axis\n",
    "predictions = np.argmax(loss_activation.output,\n",
    "                        axis=1)\n",
    "\n",
    "if len(y.shape) == 2:\n",
    "    y = np.argmax(y, axis=1)\n",
    "\n",
    "accuracy = np.mean(predictions==y)\n",
    "\n",
    "print(f\"acc: {accuracy}\")\n",
    "\n",
    "# Backward pass\n",
    "loss_activation.backward(loss_activation.output, y)\n",
    "dense2.backward(loss_activation.dinputs)\n",
    "activation1.backward(dense2.dinputs)\n",
    "dense1.backward(activation1.dinputs)\n",
    "\n",
    "# Print gradients\n",
    "print(dense1.dweights)\n",
    "print(dense1.dbiases)\n",
    "print(dense2.dweights)\n",
    "print(dense2.dbiases)\n"
   ],
   "id": "11912a22544995aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333355 0.33333322 0.3333332 ]\n",
      " [0.33333382 0.33333313 0.3333331 ]\n",
      " [0.3333341  0.33333302 0.33333293]\n",
      " [0.33333433 0.3333329  0.33333278]]\n",
      "loss: 1.098608136177063\n",
      "acc: 0.33666666666666667\n",
      "[[ 3.3042497e-06 -3.9488214e-06 -9.9410361e-05]\n",
      " [-2.2006869e-05  3.0671345e-04  1.6974623e-04]]\n",
      "[[-1.8163289e-05 -5.1999162e-04  1.4667885e-05]]\n",
      "[[ 9.1446236e-05 -2.5220119e-04  1.6075491e-04]\n",
      " [-1.7278348e-04  3.9700870e-04 -2.2422521e-04]\n",
      " [ 4.4883698e-05 -1.2783038e-04  8.2946666e-05]]\n",
      "[[ 4.6649948e-06 -8.3957566e-06  3.5949051e-06]]\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "38db4668ebb72c32"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
